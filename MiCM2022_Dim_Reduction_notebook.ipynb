{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7041c7b",
   "metadata": {},
   "source": [
    "# Introduction to Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e36797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1ed79",
   "metadata": {},
   "source": [
    "#### A walk on the beach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9911dc",
   "metadata": {},
   "source": [
    "<img src=\"beach.jpeg\" width=\"600\">\n",
    "<div style=\"text-align: center\"> source: https://www.publicdomainpictures.net/en/free-download.php?image=shadows-on-the-beach&id=177457 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3c5e1",
   "metadata": {},
   "source": [
    "#### Looking for repetition: a recipe book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315669e7",
   "metadata": {},
   "source": [
    "<img src=\"recipes.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbed629",
   "metadata": {},
   "source": [
    "<img src=\"recipes2.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bb0d1",
   "metadata": {},
   "source": [
    "#### Nonlinearities during dimensionality reduction: calculating body mass index\n",
    "\n",
    "The body mass index (BMI) is calculated form a person's height and weight as an indicator of body composition. The BMI is calculated as follows:\n",
    "\n",
    "$$\n",
    "BMI = \\frac{weight}{height^2}\n",
    "$$\n",
    "\n",
    "The units of BMI are therefore $m / kg^2$. Calculating BMI has the benefit of reducing two variables into a single variable, amounting to dimensionality reduction.\n",
    "\n",
    "Now, could we say that calculating BMI amounts to *linear* dimensionality reduction?\n",
    "\n",
    "How about the following?\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "l.BMI = log(BMI) &= log(\\frac{weight}{height^2})\\\\\n",
    "&= log(weight) - log(height^2)\\\\\n",
    "&= log(weight) - 2log(height)\\\\\n",
    "&= l.weight - l.height\\\\\n",
    "\\\\\n",
    "l.BMI &= l.weight - l.height\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=[7,3.5])\n",
    "\n",
    "heights = np.linspace(1.5, 2.1, 100)\n",
    "weights = np.linspace(50, 120, 100)\n",
    "hv, wv = np.meshgrid(heights, weights)\n",
    "bmisv = wv / hv**2\n",
    "hwb = np.stack([hv.flatten(), wv.flatten(), bmisv.flatten()]).T\n",
    "\n",
    "log_heights = np.log(np.linspace(1.5, 2.1, 100))\n",
    "log_weights = np.log(np.linspace(50, 120, 100))\n",
    "lhv, lwv = np.meshgrid(log_heights, log_weights)\n",
    "log_bmisv = lwv - 2*lhv\n",
    "log_hwb = np.stack([lhv.flatten(), lwv.flatten(), log_bmisv.flatten()]).T\n",
    "\n",
    "s0 = ax[0].contourf(hv, wv, bmisv); ax[0].set_xlabel('height (m)'); ax[0].set_ylabel('weight (kg)')\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cbar0 = fig.colorbar(s0, cax=cax, orientation='vertical')\n",
    "cbar0.ax.set_title('BMI ($kg/m^2$)')\n",
    "\n",
    "s1 = ax[1].contourf(lhv, lwv, log_bmisv); ax[1].set_xlabel('log height (m)'); ax[1].set_ylabel('log weight (kg)')\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cbar1 = fig.colorbar(s1, cax=cax, orientation='vertical')\n",
    "cbar1.ax.set_title('log BMI ($kg/m^2$)')\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd6c7b",
   "metadata": {},
   "source": [
    "### Principal Components Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c95f87",
   "metadata": {},
   "source": [
    "<img src=\"pca.png\" width=\"800\">\n",
    "<div style=\"text-align: center\"> source: https://www.publicdomainpictures.net/en/free-download.php?image=shadows-on-the-beach&id=177457 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54091a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import iris dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ceb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store data in pandas DataFrame\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "iris_df['target'] = iris_df['target'].map({0:iris.target_names[0], 1:iris.target_names[1], 2:iris.target_names[2]})\n",
    "iris_df.rename(columns = {'target':'species'}, inplace=True)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab637e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract numerical values in arrays\n",
    "x = iris_df.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize data: zero mean & unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x = StandardScaler().fit_transform(x)\n",
    "x_trunc = x[:,:-1]  ## first three features, for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8210735",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize truncated data containing first three features\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\", elev=-150, azim=110)\n",
    "ax.scatter(x_trunc[:,0], x_trunc[:,1], x_trunc[:,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad03174",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare 2D projections of full vs truncated data\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=[6.,6.])\n",
    "ax.set_xlabel('PCA 1'); ax.set_ylabel('PCA 2')\n",
    "ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "## 2D PCA projection of truncated data\n",
    "pca = PCA(n_components=2)\n",
    "x_2d = pca.fit_transform(x_trunc)\n",
    "ax.scatter(x_2d[:,0], x_2d[:,1])\n",
    "\n",
    "## 2D PCA projection of full data\n",
    "pca = PCA(n_components=2)\n",
    "x_2d = pca.fit_transform(x)\n",
    "ax.scatter(x_2d[:,0], x_2d[:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare \"manual\" 2D projection to automatic 2D projection\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=[6.,6.])\n",
    "ax.set_xlabel('PCA 1'); ax.set_ylabel('PCA 2')\n",
    "ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "## 2D PCA projection of full data\n",
    "pca = PCA(n_components=2)\n",
    "x_2d = pca.fit_transform(x)\n",
    "ax.scatter(x_2d[:,0], x_2d[:,1])\n",
    "\n",
    "## 2D PCA projection of full data - matrix multiplication\n",
    "x_2d_manual = x @ pca.components_.T\n",
    "ax.scatter(x_2d_manual[:,0], x_2d_manual[:,1]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show 2D projection alongside weights for different features\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=[12.,5.])\n",
    "ax[0].set_xlabel('PCA 1 ({:.2})'.format(pca.explained_variance_ratio_[0]))  # proportion of variance explained by PCA component 1\n",
    "ax[0].set_ylabel('PCA 2 ({:.2})'.format(pca.explained_variance_ratio_[1]))  # proportion of variance explained by PCA component 2\n",
    "ax[0].set_xticks([]); ax[0].set_yticks([])\n",
    "\n",
    "x_2d_manual = x @ pca.components_.T\n",
    "ax[0].scatter(x_2d_manual[:,0], x_2d_manual[:,1]);\n",
    "\n",
    "## Barplot of components' weights\n",
    "bp = pd.DataFrame(pca.components_, columns=iris_df.columns[:-1].str.strip(' (cm)'), index=['PCA 1', 'PCA 2']).plot.bar(ax=ax[1], rot=0);\n",
    "bp.set_ylabel('weights');\n",
    "for p in ax[1].patches:\n",
    "    ax[1].annotate(str(round(p.get_height(), 2)), (p.get_x()-0.005, p.get_height()*1.025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Manual\" 2D projection - project dimensions individually\n",
    "\n",
    "xi = x[0,:]\n",
    "print(xi)\n",
    "\n",
    "xi_1 = (xi * pca.components_[0,:]).sum()  # project onto 1st component\n",
    "xi_2 = (xi * pca.components_[1,:]).sum()  # project onto 2nd component\n",
    "\n",
    "print(np.float32([xi_1, xi_2]))\n",
    "print(np.float32(x_2d[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba728f",
   "metadata": {},
   "source": [
    "#### Kernel PCA and Probabilistic PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1322543",
   "metadata": {},
   "source": [
    "PCA provides *linear* components which can be unsuitable for data with non-linear structures. Non-linear functions called *kernels* can be used to represent data such that PCA can provide suitable linear components of that non-linear representation. This method is termed **kernel PCA**.\n",
    "\n",
    "<img src=\"kpca.png\" width=\"900\">\n",
    "<div style=\"text-align: center\"> source: https://www.cs.mcgill.ca/~dprecup/courses/ML/Lectures/ml-lecture13.pdf </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8a29d",
   "metadata": {},
   "source": [
    "PCA does not attempt to model noise which accompany its components. In **probabilistic PCA**, a noise variance term $\\sigma^2$ accounts for random variations within its components, allowing projections against its components with varying spreads. Probabilistic PCA can thus model both the linear structure and noise components of its components. Due to its probabilistic nature, probabilistic PCA can also be used as a generative model.\n",
    "\n",
    "<img src=\"ppca.png\" width=\"1000\">\n",
    "<div style=\"text-align: center\"> source: https://www.youtube.com/watch?v=lJ0cXPoEozg </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e264a72",
   "metadata": {},
   "source": [
    "#### Independent Component Analysis (ICA)\n",
    "\n",
    "PCA provides *orthogonal* components / coordinates, which can limit the modelling capacities of PCA. On the other hand, such ICA components are not constrained to be orthogonal which provides ICA with more \"flexibility\".\n",
    "\n",
    "<img src=\"pca_vs_ica.png\" width=\"800\">\n",
    "<div style=\"text-align: center\"> source: https://brainvision.com/applications/eeg/ </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c43870c",
   "metadata": {},
   "source": [
    "#### Electroencephalography (EEG) data analysis\n",
    " \n",
    " The EEG is a brain recording modality where electrodes are placed on the scalp/head to measure fluctuations in bioelectical potentials. Hence, every electrode measures a time-varying signal.\n",
    " \n",
    "  <img src=\"eeg_image.png\" width=\"400\">\n",
    "  <div style=\"text-align: center\"> source: https://brainvision.com/applications/eeg/ </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d5c29",
   "metadata": {},
   "source": [
    "Import EEG data using [MNE Python](https://mne.tools/stable/index.html) analysis package. We will be using open-source data which has been reported in:\n",
    "\n",
    "[Babayan, A., Erbey, M., Kumral, D. et al. *A mind-brain-body dataset of MRI, EEG, cognition, emotion, and peripheral physiology in young and old adults.* Sci Data 6, 180308 (2019).](https://www.nature.com/articles/sdata2018308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a29b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load EEG data\n",
    "eeg = mne.io.read_raw_eeglab(\"sub-010321_EC_downsamp.set\")\n",
    "eeg.annotations.delete( np.arange( len(eeg.annotations.description) ) )  # remove annotations, not important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446de7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot EEG electrode layout and EEG signals\n",
    "eeg.plot_sensors(show_names=True, sphere=90);\n",
    "eeg.plot(n_channels=12, duration=4);  # recommend plotting using \"notebook\" plotting backend, i.e. %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ea1b6",
   "metadata": {},
   "source": [
    "From the time-series plots, it seems that many time-series are alike. Perhaps there's a way to find patterns and have a more succinct representation of our data. One way to find these patterns is to use **Independent Components Analysis** (ICA) on our EEG data.\n",
    "\n",
    "  <img src=\"eeg_ica.jpeg\" width=\"500\">\n",
    "  <div style=\"text-align: center\"> source: https://sccn.ucsd.edu/~jung/Site/EEG_artifact_removal.html </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute ICA on EEG data\n",
    "num_comps = 15  # choose number of patterns, or \"components\"\n",
    "\n",
    "ica = ICA(n_components=num_comps, random_state=97)\n",
    "ica.fit(eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ICA components\n",
    "ica.plot_sources(eeg, start=10, stop=16);\n",
    "ica.plot_components();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7adf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute PCA on EEG data\n",
    "num_comps = 15  # choose number of patterns, or \"components\"\n",
    "\n",
    "eeg_ts = eeg.get_data().T\n",
    "pca = PCA(n_components=num_comps)\n",
    "pca_data_ts = pca.fit_transform(eeg_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5818394",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot PCA components\n",
    "len_plot = 1000     # choose time-series length for plotting purposes\n",
    "\n",
    "num_plots = pca_data_ts.shape[1]\n",
    "plt.figure(figsize=[9.,9.])\n",
    "\n",
    "for i in range(num_plots):\n",
    "    ax = plt.subplot( num_plots , 1, i+1 )\n",
    "    plt.plot(zscore(pca_data_ts)[:len_plot,i])\n",
    "    \n",
    "    ax.set_ylabel(\"PCA {}\".format(i), fontsize=8, rotation=0)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750db33",
   "metadata": {},
   "source": [
    "### Nonlinear dimensionality reduction: t-SNE and UMAP\n",
    "\n",
    "Linear dimensionality reduction methods such as PCA may be incapable of properly displaying data in a low-dimensional space (e.g. 2D). As previously discussed, kernel PCA leverages nonlinear transformations (i.e. kernels) such that the resulting representation is ammenable to standard PCA. However, kernel PCA requires a pre-defined kernel function to obtain a suitable nonlinear representation.\n",
    "\n",
    "We will now explore two nonlinear dimensionality reduction methods which do not require such pre-defined kernels. These are:\n",
    "1. t-distributed Stochastic Neighbor Embedding (**t-SNE**)\n",
    "2. Uniform Manifold Approximation and Projection (**UMAP**)\n",
    "\n",
    "t-SNE and UMAP are often used in the analysis of single-cell RNA sequencing (scRNA-seq) data which is very high dimensional, e.g. d = 20'000 genes. scRNA-seq data from the mouse prancreas will be used here for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scanpy as sc\n",
    "import random\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and format data\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "# mouse pancreas single-cell dataset\n",
    "# read in data and cell type labels\n",
    "with open('MP.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "with open('MP_genes.pickle', 'rb') as f:\n",
    "    genes = pickle.load(f)\n",
    "\n",
    "df.set_index('Unnamed: 0', inplace=True)  # set first column (cell ID as the index column)\n",
    "sample_id = pickle.load(open('cell_IDs.pkl', 'rb'))\n",
    "df = df.loc[list(sample_id), :]\n",
    "\n",
    "X = df[genes].values  # extract the N x M cells-by-genes matrix\n",
    "\n",
    "sample_info = pd.read_csv('sample_info.csv')\n",
    "\n",
    "mp_anndata = anndata.AnnData(X=X)\n",
    "mp_anndata.obs['Celltype'] = sample_info['assigned_cluster'].values\n",
    "celltype_one_hot = pd.get_dummies(mp_anndata.obs['Celltype'], prefix='Celltype').values\n",
    "\n",
    "N = X.shape[0]  # number of single-cell samples\n",
    "K = len(sample_info['assigned_cluster'].unique())  # number of topics\n",
    "M = X.shape[1]  # number of genes\n",
    "\n",
    "mp_anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e31d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute and plot 2D t-SNE projection\n",
    "_, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "sc.tl.tsne(mp_anndata, perplexity=50)\n",
    "sc.pl.tsne(mp_anndata, color=[\"Celltype\"], ax=ax, title='two-dimensional tSNE plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfa0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute neighbor affinities\n",
    "sc.pp.neighbors(mp_anndata, n_neighbors=30)\n",
    "\n",
    "## Compute and plot 2D UMAP projection\n",
    "_, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "sc.tl.umap(mp_anndata, min_dist=0.1)\n",
    "sc.pl.umap(mp_anndata, color=[\"Celltype\"], ax=ax, title='two-dimensional UMAP plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07098420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0772f131",
   "metadata": {},
   "source": [
    "### Autoencoders\n",
    "Adapted from: https://www.theaidream.com/post/an-introduction-to-autoencoder-and-variational-autoencoder-vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98170d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2163369",
   "metadata": {},
   "source": [
    "Vanilla AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d19162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the size of our encoded representations\n",
    "encoding_dim = 2  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "hidden_dim = 64\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_enc = layers.Dense(hidden_dim, activation='relu')(input_img)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(hidden_enc)\n",
    "ae_encoder = keras.Model(input_img, encoded, name='encoder')\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "encoded_inputs = keras.Input(shape=(encoding_dim,), name='z_sampling')\n",
    "hidden_dec = layers.Dense(hidden_dim, activation='relu')(encoded_inputs)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(hidden_dec)\n",
    "ae_decoder = keras.Model(encoded_inputs, decoded, name='decoder')\n",
    "\n",
    "output_img = ae_decoder(ae_encoder(input_img))\n",
    "\n",
    "autoencoder = keras.Model(input_img, output_img, name='ae')\n",
    "\n",
    "#Now let's train our autoencoder to reconstruct MNIST digits.\n",
    "#First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adam optimizer:\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "#Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images).\n",
    "\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784.\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "#Now let's train our autoencoder for 50 epochs:\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "#After 50 epochs, the autoencoder seems to reach a stable train/validation loss value of about 0.09. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib.\n",
    "\n",
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "\n",
    "encoded_imgs = ae_encoder.predict(x_test)\n",
    "decoded_imgs = ae_decoder.predict(encoded_imgs)\n",
    "n = 10  # Number of digits to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "# Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "x_test_encoded = ae_encoder.predict(x_test, verbose=0)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=y_test, cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10614734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# We will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.flip(np.linspace(0, 120, n))\n",
    "grid_y = np.linspace(0, 100, n)\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = ae_decoder.predict(z_sample, verbose=0)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc01fe3",
   "metadata": {},
   "source": [
    "Variational AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, here's our encoder network, mapping inputs to our latent distribution parameters:\n",
    "original_dim = 28 * 28\n",
    "intermediate_dim = 64\n",
    "latent_dim = 2\n",
    "\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)\n",
    "\n",
    "#We can use these parameters to sample new similar points from the latent space:\n",
    "from keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "#Finally, we can map these sampled latent points back to reconstructed inputs:\n",
    "# Create encoder\n",
    "vae_encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "vae_decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# Instantiate VAE model\n",
    "outputs = vae_decoder(vae_encoder(inputs)[2])\n",
    "\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "#We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term.\n",
    "\n",
    "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "\n",
    "#We train our VAE on MNIST digits:\n",
    "vae.fit(x_train, x_train,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf58822",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "x_test_encoded = vae_encoder.predict(x_test, verbose=0)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[0][:,0], x_test_encoded[0][:,1], c=y_test, cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "# We will sample n points within [-15, 15]\n",
    "grid_x = np.flip(np.linspace(-3, 3, n))\n",
    "grid_y = np.linspace(-3, 3, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = vae_decoder.predict(z_sample, verbose=0)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331a60d",
   "metadata": {},
   "source": [
    "### Other topics in dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac234e",
   "metadata": {},
   "source": [
    "1. Dimensionality reduction via latent associations between datasets\n",
    "2. Tensor decompositions\n",
    "3. Dimensinality reduction of autocorrelated data\n",
    "4. Categorical and mixed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a651d61",
   "metadata": {},
   "source": [
    "1. Latent associations between two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc86a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea41213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62f059d4",
   "metadata": {},
   "source": [
    "#### Sandbox"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimred_py",
   "language": "python",
   "name": "dimred_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
